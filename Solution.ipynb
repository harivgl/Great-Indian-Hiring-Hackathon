{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sympy import symbols, solve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the train and test data path according to your PC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create numeric feature for Date and assign UnitPrice column of NaN to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.InvoiceDate = pd.to_datetime(df.InvoiceDate)\n",
    "test.InvoiceDate = pd.to_datetime(test.InvoiceDate)\n",
    "\n",
    "df['Date'] = (df.InvoiceDate - pd.Timestamp(\"2010-01-01\")) / pd.Timedelta(days=1)\n",
    "test['Date'] = (test.InvoiceDate - pd.Timestamp(\"2010-01-01\")) / pd.Timedelta(days=1)\n",
    "\n",
    "test['UnitPrice'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe with UnitPrice details of each stock code in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = df.groupby('StockCode').agg(n=pd.NamedAgg(column='UnitPrice', aggfunc=lambda x:x.nunique()),\n",
    "                            values=pd.NamedAgg(column='UnitPrice', aggfunc=lambda x:x.unique()),\n",
    "                            vcounts=pd.NamedAgg(column='UnitPrice', aggfunc=lambda x:x.value_counts()),\n",
    "                            ndesc=pd.NamedAgg(column='Description', aggfunc=lambda x:x.nunique()))\n",
    "\n",
    "sp['weighted'] = (sp['values']*sp['vcounts']).map(lambda x:np.sum(x)) / sp['vcounts'].map(lambda x: np.sum(x))\n",
    "sp.n = sp.n.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a pandas series with index as number of unique UnitPrices and values as corresponding StockCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocksbynvalues = sp.sort_values('n').reset_index().groupby('n').StockCode.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the StockCodes with only 1 unique UnitPrice, directly map the values to solution. 8084 / 122049 rows predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['UnitPrice'] = test.StockCode.map(sp[sp.n==1]['values'].to_dict()).dropna().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to map a value to the closest value in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    if type(array) == float:\n",
    "        return value\n",
    "    if type(array) == np.float64:\n",
    "        array = np.asarray([array])\n",
    "    else:    \n",
    "        array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model to predict UnitPrices of StockCodes with number of unique values from 2 to 11 with seperate models and hyperparameters for each set. Predictions also mapped to nearest value possible in that StockCode. Results finally assigned to solution. 113339 / 122049 rows predicted. Overall 121423 rows predicted. Only 626 rows remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypdict = {2:(1,10,2),3:(0.9,10,1),4:(1,10,2),5:(0.9,10,4),6:(1,10,4),7:(0.9,10,4),8:(0.9,10,1),9:(0.9,20,4),11:(1,10,4)}\n",
    "\n",
    "for idx,j in (stocksbynvalues.loc[2:11]).items():\n",
    "    k,l,m = hypdict[idx]\n",
    "    for i in j:    \n",
    "        above1df = df[df.StockCode==i].drop(['InvoiceDate','InvoiceNo'],axis=1).copy()\n",
    "        above1dfX = above1df.drop('UnitPrice',axis=1)\n",
    "        above1dfy = above1df['UnitPrice']\n",
    "\n",
    "        mean_enc_column_names = ['StockCode','Description','CustomerID','Country']\n",
    "        targenc = category_encoders.TargetEncoder(cols=mean_enc_column_names)\n",
    "\n",
    "       \n",
    "        xgbr = XGBRegressor(colsample_bytree=k ,gamma= 0,learning_rate= 0.1,max_depth= l,min_child_weight= m,n_estimators= 300,subsample= 0.9,verbosity=0)\n",
    "        pipe = Pipeline(steps=[('e', targenc), ('m', xgbr)])\n",
    "        pipe.fit(above1dfX , above1dfy)\n",
    "\n",
    "        above1test = test[test.StockCode==i].drop(['InvoiceDate','InvoiceNo','UnitPrice'],axis=1).copy()\n",
    "        temp = test[test.StockCode==i][['UnitPrice']].copy()\n",
    "        temp['UnitPrice'] = pipe.predict(above1test)\n",
    "        temp['UnitPrice'] = temp.apply(lambda x: find_nearest(sp.loc[i,'values'], x['UnitPrice']), axis=1)\n",
    "        \n",
    "        test.loc[temp.index,'UnitPrice'] = temp['UnitPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StockCodes only present in test set can be approximated with nearby StockCodes in train set. Predict the values and assign to solution. 91 rows predicted. 535 remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknstock = test[~test.StockCode.isin([3678,3679,3680,3681,3683])][test.UnitPrice.isna()][['StockCode']].copy()\n",
    "\n",
    "test.loc[unknstock.index,'UnitPrice'] = unknstock.StockCode.apply(lambda x:sp.loc[find_nearest(sp.index,x),'weighted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a month feature in train and test set by combining month number and year number from InvoiceDate into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = (df.InvoiceDate.dt.month.astype('str') + df.InvoiceDate.dt.year.astype('str')).astype('category')\n",
    "test['month'] = (test.InvoiceDate.dt.month.astype('str') + test.InvoiceDate.dt.year.astype('str')).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StockCodes 3678 and 3680 only have one and the same customer and are strongly correlated with Date. Model to predict their values and assign to solution. 6 rows predicted. 529 remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "above1df = df[df.StockCode.isin([3678,3680])][['StockCode','Quantity','Date','month','UnitPrice']].copy()\n",
    "above1dfX = above1df.drop('UnitPrice',axis=1)\n",
    "above1dfy = above1df['UnitPrice']\n",
    "\n",
    "mean_enc_column_names = ['month','StockCode']\n",
    "targenc = category_encoders.OneHotEncoder(cols=mean_enc_column_names)\n",
    "\n",
    "xgbr = XGBRegressor(colsample_bytree=1 ,gamma= 0,learning_rate= 1,max_depth= 15,min_child_weight= 1,n_estimators= 300,subsample= 1,verbosity=0)\n",
    "pipe = Pipeline(steps=[('e', targenc), ('m', xgbr)])\n",
    "pipe.fit(above1dfX , above1dfy)\n",
    "\n",
    "above1test = test[test.StockCode.isin([3678,3680])][['StockCode','Quantity','Date','month']].copy()\n",
    "temp = test[test.StockCode.isin([3678,3680])][['UnitPrice']].copy()\n",
    "temp['UnitPrice'] = pipe.predict(above1test)\n",
    "\n",
    "test.loc[temp.index,'UnitPrice'] = temp['UnitPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next last 3 StockCodes were the most tricky and time consuming. In my exploratory analysis I observed that  Stocks 3679 and 3683 had extreme outliers and that 3679’s outlier matched as a pair(+1 & -1 quantity from same customer in the same day) to a test entry for Stock 3681! So these was a possibility for mixing. Also I observed  that a lot of high value transactions occurred in pairs, ie. The same customer usually in the same day(not always) having the same + and – quantity for 2 transactions with same UnitPrice. It could be handpicked but I wanted to make a model to detect such pairs and predict them accurately. I made a  dataset with the full 3681 data combined with 3679 and 3683 data where the UnitPrice z-score exceeded 3. I made a custom algorithm combined with an XGBRegressor to predict such pair values. Detailed code is below. 'StockCode', 'InvoiceNo', 'Quantity' and 'Date' was used on a custom built train and test set derived using the dataset created earlier. 'InvoiceNo' was first label encoded and then OneHot encoded along with 'StockCode' and 'Quantity'.\n",
    "27 rows were predicted using this model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3679 = np.abs(zscore(df[df.StockCode.isin([3679])].UnitPrice))\n",
    "z3683 = np.abs(zscore(df[df.StockCode.isin([3683])].UnitPrice))\n",
    "largedf = df[df.StockCode==3681].append(df[df.StockCode==3679][z3679>=3]).append(df[df.StockCode==3683][z3683>=3]).copy()\n",
    "largetest = test[test.StockCode.isin([3679,3681,3683])][test.CustomerID.isin(largedf.CustomerID)].copy()\n",
    "\n",
    "largedf['Dateint'] = largedf.Date.astype('int')\n",
    "largetest['Dateint'] = largetest.Date.astype('int')\n",
    "largetest['Quantopp'] = -1*largetest.Quantity\n",
    "largedf['Quantopp'] = -1*largedf.Quantity\n",
    "\n",
    "largetest = largetest[largetest[['Quantopp','CustomerID']].apply(tuple,axis=1).isin(largedf[['Quantity','CustomerID']].apply(tuple,axis=1))]\n",
    "largedf = largedf[largedf.CustomerID.isin(largetest.CustomerID)]\n",
    "\n",
    "largedf = largedf.sort_values(['CustomerID','UnitPrice','Quantopp'])\n",
    "largedf[\"check\"] = largedf.groupby([\"CustomerID\", \"UnitPrice\"]).Quantity.cumsum()\n",
    "largedf[\"check\"] = np.where(largedf.check != 0, np.nan, largedf.check)\n",
    "largedf[\"check\"] = largedf[\"check\"].bfill(limit=1)\n",
    "largedf[\"numrows\"] = largedf.groupby('CustomerID')['StockCode'].transform(lambda x:x.value_counts().max())\n",
    "largedf = largedf[largedf.numrows<=10]\n",
    "largedf = largedf.loc[~(largedf.duplicated([\"CustomerID\", \"UnitPrice\"], keep=False) & (largedf.check == 0))]\n",
    "\n",
    "largetest = largetest.sort_values(['CustomerID','InvoiceDate','Quantopp'])\n",
    "largetest[\"check\"] = largetest.groupby([\"CustomerID\", \"Dateint\"]).apply(lambda x:x.loc[::-1, 'Quantity'].cumsum()[::-1]).values\n",
    "largetest[\"check\"] = np.where(largetest.check != 0, np.nan, largetest.check)\n",
    "largetest[\"check\"] = largetest[\"check\"].ffill(limit=1)\n",
    "largetest = largetest.loc[~(largetest.duplicated([\"CustomerID\", \"Dateint\"], keep=False) & (largetest.check == 0))]\n",
    "\n",
    "othercatcust = np.concatenate([df[df.StockCode==3679][z3679>=3].CustomerID.unique() , df[df.StockCode==3683][z3683>=3].CustomerID.unique()])\n",
    "largetest = largetest[(largetest.StockCode==3681)|(largetest.CustomerID.isin(othercatcust))]\n",
    "\n",
    "largedf = largedf[~(largedf.duplicated(subset=['InvoiceDate'],keep='last'))]\n",
    "largedf = largedf[largedf.UnitPrice>=4]\n",
    "\n",
    "largedf = largedf[largedf[['Quantopp','CustomerID']].apply(tuple,axis=1).isin(largetest[['Quantity','CustomerID']].apply(tuple,axis=1))]\n",
    "largetest = largetest[largetest.CustomerID.isin(largedf.CustomerID.unique())]\n",
    "\n",
    "labenc = LabelEncoder()\n",
    "\n",
    "for i in largetest.CustomerID.unique():\n",
    "    above1df = largedf[largedf.CustomerID==i][['StockCode','InvoiceNo','Quantity','Date','UnitPrice']].copy()\n",
    "    above1dfX = above1df.drop('UnitPrice',axis=1)\n",
    "    above1dfX['InvoiceNo'] = labenc.fit_transform(above1dfX['InvoiceNo'])\n",
    "    above1dfy = above1df['UnitPrice']\n",
    "\n",
    "    \n",
    "    mean_enc_column_names = ['InvoiceNo','StockCode','Quantity'] \n",
    "    targenc = category_encoders.OneHotEncoder(cols=mean_enc_column_names)\n",
    "\n",
    "    xgbr = XGBRegressor(colsample_bytree=1 ,gamma= 0,learning_rate= 1,max_depth= 15,min_child_weight= 1,n_estimators= 1000,subsample= 1,verbosity=0)\n",
    "    pipe = Pipeline(steps=[('e', targenc), ('m', xgbr)])\n",
    "    pipe.fit(above1dfX , above1dfy)\n",
    "\n",
    "    above1test = largetest[largetest.CustomerID==i][['StockCode','InvoiceNo','Quantity','Date']].copy()\n",
    "    above1test['InvoiceNo'] = labenc.fit_transform(above1test['InvoiceNo'])\n",
    "    temp = largetest[largetest.CustomerID==i][['UnitPrice']].copy()\n",
    "    temp['UnitPrice'] = pipe.predict(above1test)\n",
    "    \n",
    "    test.loc[temp.index,'UnitPrice'] = temp['UnitPrice'].round(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining non high value Stocks from train and test set. ie.,rows predicted till now in test (StockCodes<3678). Also adding a sale amount feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = df[~df.StockCode.isin([3678,3679,3680,3681,3683])].append(test[~test.StockCode.isin([3678,3679,3680,3681,3683])]).copy()\n",
    "fulldata['sale'] = fulldata.Quantity * fulldata.UnitPrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating monthly sales for each Customer and filling missing months with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlysalescust = pd.DataFrame()\n",
    "for i in fulldata.CustomerID.unique():\n",
    "    monthlysalescust = monthlysalescust.append(pd.Series({'CustomerID':i}).append(fulldata[fulldata.CustomerID==i].resample('M',on='InvoiceDate')['sale'].sum()).to_frame().T)\n",
    "    \n",
    "monthlysalescust.columns = ['CustomerID', '22011', '32011',\n",
    "                               '42011', '52011', '62011',\n",
    "                               '72011', '82011', '92011',\n",
    "                               '102011', '112011', '122011',\n",
    "                               '12011', '122010']\n",
    "monthlysalescust = monthlysalescust.set_index('CustomerID')  \n",
    "monthlysalescust.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating several features in the full combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['hourq'],hourbin = pd.qcut(fulldata.InvoiceDate.dt.hour,7,retbins=True,labels=[1,2,3,4,5,6,7])\n",
    "fulldata['monthq'],monthbin=pd.qcut(fulldata.InvoiceDate.dt.month,6,retbins=True,labels=[1,2,3,4,5,6])\n",
    "fulldata['weekdayq'],weekdaybin=pd.qcut(fulldata.InvoiceDate.dt.dayofweek,3,retbins=True,labels=[1,2,3])\n",
    "fulldata['monthstart'] = fulldata.InvoiceDate.dt.is_month_start\n",
    "fulldata['diffcountry'] = np.where(fulldata.Country==35,0,1)  \n",
    "\n",
    "fulldata['monthlysalescust'] = fulldata.apply(lambda x:monthlysalescust.loc[x.CustomerID,x.month] if x.CustomerID in monthlysalescust.index else 0 ,axis=1)\n",
    "fulldata['totalsalescust'] = fulldata.groupby('CustomerID')['sale'].transform('sum')\n",
    "fulldata['daysvisitedcust'] = fulldata.groupby('CustomerID')['InvoiceDate'].transform(lambda x:x.dt.date.nunique())\n",
    "fulldata['monthsvisitedcust'] = fulldata.groupby('CustomerID')['month'].transform(lambda x:x.nunique())\n",
    "fulldata['invoicenoscust'] = fulldata.groupby('CustomerID')['InvoiceNo'].transform(lambda x:x.nunique())\n",
    "fulldata['transacnoscust'] = fulldata.groupby('CustomerID')['InvoiceNo'].transform('count')\n",
    "fulldata['avgspendpertranscust'] = fulldata['totalsalescust'] / fulldata['transacnoscust']\n",
    "fulldata['avgspendperinvoicecust'] = fulldata['totalsalescust'] / fulldata['invoicenoscust']\n",
    "fulldata['avgspendperdaycust'] = fulldata['totalsalescust'] / fulldata['daysvisitedcust']\n",
    "fulldata['avgspendpermonthcust'] = fulldata['totalsalescust'] / fulldata['monthsvisitedcust']\n",
    "fulldata['custsince'] = fulldata.groupby('CustomerID')['InvoiceDate'].transform(lambda x:x.dt.date.min()).apply(lambda x:( pd.Timestamp(\"2011-12-31\") - pd.Timestamp(x) ) / pd.Timedelta(days=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a Customer details dataframe from the fulldata dataframe, with one row for each Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "custdetails = fulldata[~fulldata.duplicated(subset='CustomerID')][['CustomerID',\n",
    "       'totalsalescust', 'daysvisitedcust', 'monthsvisitedcust',\n",
    "       'invoicenoscust', 'transacnoscust', 'avgspendpertranscust',\n",
    "       'avgspendperinvoicecust', 'avgspendperdaycust', 'avgspendpermonthcust',\n",
    "       'custsince']].set_index('CustomerID').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model to predict the values of StockCode 3679 items by creating new feature engineered train and test set. One outlier row in 3679 train has corresponding pair value in 3681 test, so dropping it. Also assigning a couple of outlier values with trends from train set. Assign values to solution. 28 rows predicted. 501 remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3679 = df[df.StockCode==3679].copy()\n",
    "train3679.drop(65239,inplace=True)\n",
    "test3679 = test[test.StockCode==3679][test.UnitPrice.isnull()].copy()\n",
    "\n",
    "train3679['hourq']= pd.cut(train3679.InvoiceDate.dt.hour,bins=hourbin,include_lowest=True,labels=[1,2,3,4,5,6,7],ordered=False)\n",
    "train3679['monthq']=pd.cut(train3679.InvoiceDate.dt.month,bins=monthbin,include_lowest=True,labels=[1,2,3,4,5,6],ordered=False)\n",
    "train3679['weekdayq']=pd.cut(train3679.InvoiceDate.dt.dayofweek,bins=weekdaybin,include_lowest=True,labels=[1,2,3],ordered=False)\n",
    "train3679['monthstart'] = train3679.InvoiceDate.dt.is_month_start\n",
    "train3679['diffcountry'] = np.where(train3679.Country==35,0,1)     \n",
    "\n",
    "train3679['monthlysalescust'] = train3679.apply(lambda x:monthlysalescust.loc[x.CustomerID,x.month] if x.CustomerID in monthlysalescust.index else monthlysalescust.mean()[x.month],axis=1)\n",
    "train3679['totalsalescust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'totalsalescust'] if x.CustomerID in custdetails.index else custdetails.mean()['totalsalescust'],axis=1)\n",
    "train3679['daysvisitedcust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'daysvisitedcust'] if x.CustomerID in custdetails.index else custdetails.mean()['daysvisitedcust'],axis=1)\n",
    "train3679['monthsvisitedcust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'monthsvisitedcust'] if x.CustomerID in custdetails.index else custdetails.mean()['monthsvisitedcust'],axis=1)\n",
    "train3679['invoicenoscust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'invoicenoscust'] if x.CustomerID in custdetails.index else custdetails.mean()['invoicenoscust'],axis=1)\n",
    "train3679['transacnoscust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'transacnoscust'] if x.CustomerID in custdetails.index else custdetails.mean()['transacnoscust'],axis=1)\n",
    "train3679['avgspendpertranscust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpertranscust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendpertranscust'],axis=1)\n",
    "train3679['avgspendperinvoicecust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperinvoicecust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendperinvoicecust'],axis=1)\n",
    "train3679['avgspendperdaycust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperdaycust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendperdaycust'],axis=1)\n",
    "train3679['avgspendpermonthcust'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpermonthcust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendpermonthcust'],axis=1)\n",
    "train3679['custsince'] = train3679.apply(lambda x:custdetails.loc[x.CustomerID,'custsince'] if x.CustomerID in custdetails.index else custdetails.mean()['custsince'],axis=1)\n",
    "\n",
    "test3679['hourq']= pd.cut(test3679.InvoiceDate.dt.hour,bins=hourbin,include_lowest=True,labels=[1,2,3,4,5,6,7],ordered=False)\n",
    "test3679['monthq']=pd.cut(test3679.InvoiceDate.dt.month,bins=monthbin,include_lowest=True,labels=[1,2,3,4,5,6],ordered=False)\n",
    "test3679['weekdayq']=pd.cut(test3679.InvoiceDate.dt.dayofweek,bins=weekdaybin,include_lowest=True,labels=[1,2,3],ordered=False)\n",
    "test3679['monthstart'] = test3679.InvoiceDate.dt.is_month_start\n",
    "test3679['diffcountry'] = np.where(test3679.Country==35,0,1)     \n",
    "\n",
    "test3679['monthlysalescust'] = test3679.apply(lambda x:monthlysalescust.loc[x.CustomerID,x.month] if x.CustomerID in monthlysalescust.index else monthlysalescust.mean()[x.month],axis=1)\n",
    "test3679['totalsalescust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'totalsalescust'] if x.CustomerID in custdetails.index else custdetails.mean()['totalsalescust'],axis=1)\n",
    "test3679['daysvisitedcust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'daysvisitedcust'] if x.CustomerID in custdetails.index else custdetails.mean()['daysvisitedcust'],axis=1)\n",
    "test3679['monthsvisitedcust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'monthsvisitedcust'] if x.CustomerID in custdetails.index else custdetails.mean()['monthsvisitedcust'],axis=1)\n",
    "test3679['invoicenoscust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'invoicenoscust'] if x.CustomerID in custdetails.index else custdetails.mean()['invoicenoscust'],axis=1)\n",
    "test3679['transacnoscust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'transacnoscust'] if x.CustomerID in custdetails.index else custdetails.mean()['transacnoscust'],axis=1)\n",
    "test3679['avgspendpertranscust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpertranscust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendpertranscust'],axis=1)\n",
    "test3679['avgspendperinvoicecust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperinvoicecust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendperinvoicecust'],axis=1)\n",
    "test3679['avgspendperdaycust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperdaycust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendperdaycust'],axis=1)\n",
    "test3679['avgspendpermonthcust'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpermonthcust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendpermonthcust'],axis=1)\n",
    "test3679['custsince'] = test3679.apply(lambda x:custdetails.loc[x.CustomerID,'custsince'] if x.CustomerID in custdetails.index else custdetails.mean()['custsince'],axis=1)\n",
    "\n",
    "above1df = train3679.drop(['StockCode','Description','InvoiceDate','InvoiceNo'],axis=1).copy()\n",
    "above1dfX = above1df.drop('UnitPrice',axis=1)\n",
    "above1dfy = above1df['UnitPrice']\n",
    "\n",
    "mean_enc_column_names = ['month','Country','CustomerID','hourq', 'monthq', 'weekdayq']\n",
    "targenc = category_encoders.OneHotEncoder(cols=mean_enc_column_names)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "xgbr = XGBRegressor(colsample_bytree=0.9 ,gamma= 4,learning_rate= 0.9,max_depth= 15,min_child_weight= 1,n_estimators= 5500,subsample= 0.9,verbosity=0)\n",
    "pipe = Pipeline(steps=[('e', targenc), ('m', xgbr)])\n",
    "pipe.fit(above1dfX , above1dfy)\n",
    "\n",
    "above1test = test3679.drop(['StockCode','InvoiceDate','InvoiceNo','Description','UnitPrice'],axis=1).copy()\n",
    "test3679['UnitPrice'] = pipe.predict(above1test)\n",
    "\n",
    "test3679.loc[55737,'UnitPrice'] = train3679.loc[train3679.Quantity<=-200,'UnitPrice'].mean()\n",
    "test3679.loc[1785,'UnitPrice'] = train3679.UnitPrice.median()\n",
    "\n",
    "test.loc[test3679.index,'UnitPrice'] = test3679['UnitPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model to predict the values of StockCode 3683 items by creating new feature engineered train and test set. Train and test has a matching outlier pair, removing these 2 rows. Approximating predictions close to most common values(15,18,28,40) to the common value. Also assigning a few of outlier values with trends from train set. Assign values to solution. 356 rows predicted. 145 remain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In StockCode 3683 points, Country 32 and 31 had a maximum value of of 40 in train data. They were capped at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3683 = df[df.StockCode==3683].copy()\n",
    "test3683 = test[test.StockCode==3683][test.UnitPrice.isnull()].copy()\n",
    "train3683.drop(239556,inplace=True)\n",
    "\n",
    "test3683['month'] = (test3683.InvoiceDate.dt.month.astype('str') + test3683.InvoiceDate.dt.year.astype('str')).astype('category')\n",
    "\n",
    "train3683['hourq']= pd.cut(train3683.InvoiceDate.dt.hour,bins=hourbin,include_lowest=True,labels=[1,2,3,4,5,6,7],ordered=False)\n",
    "train3683['monthq']=pd.cut(train3683.InvoiceDate.dt.month,bins=monthbin,include_lowest=True,labels=[1,2,3,4,5,6],ordered=False)\n",
    "train3683['weekdayq']=pd.cut(train3683.InvoiceDate.dt.dayofweek,bins=weekdaybin,include_lowest=True,labels=[1,2,3],ordered=False)\n",
    "train3683['monthstart'] = train3683.InvoiceDate.dt.is_month_start\n",
    "train3683['diffcountry'] = np.where(train3683.Country.isin([13,14]),1,0)     \n",
    "\n",
    "\n",
    "train3683['monthlysalescust'] = train3683.apply(lambda x:monthlysalescust.loc[x.CustomerID,x.month] if x.CustomerID in monthlysalescust.index else 0,axis=1)\n",
    "train3683['totalsalescust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'totalsalescust'],axis=1)\n",
    "train3683['daysvisitedcust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'daysvisitedcust'],axis=1)\n",
    "train3683['monthsvisitedcust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'monthsvisitedcust'],axis=1)\n",
    "train3683['invoicenoscust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'invoicenoscust'],axis=1)\n",
    "train3683['transacnoscust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'transacnoscust'],axis=1)\n",
    "train3683['avgspendpertranscust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpertranscust'],axis=1)\n",
    "train3683['avgspendperinvoicecust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperinvoicecust'],axis=1)\n",
    "train3683['avgspendperdaycust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperdaycust'],axis=1)\n",
    "train3683['avgspendpermonthcust'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpermonthcust'],axis=1)\n",
    "train3683['custsince'] = train3683.apply(lambda x:custdetails.loc[x.CustomerID,'custsince'],axis=1)\n",
    "\n",
    "\n",
    "test3683['hourq']= pd.cut(test3683.InvoiceDate.dt.hour,bins=hourbin,include_lowest=True,labels=[1,2,3,4,5,6,7],ordered=False)\n",
    "test3683['monthq']=pd.cut(test3683.InvoiceDate.dt.month,bins=monthbin,include_lowest=True,labels=[1,2,3,4,5,6],ordered=False)\n",
    "test3683['weekdayq']=pd.cut(test3683.InvoiceDate.dt.dayofweek,bins=weekdaybin,include_lowest=True,labels=[1,2,3],ordered=False)\n",
    "test3683['monthstart'] = test3683.InvoiceDate.dt.is_month_start\n",
    "test3683['diffcountry'] = np.where(test3683.Country.isin([13,14]),1,0) \n",
    "\n",
    "\n",
    "test3683['monthlysalescust'] = test3683.apply(lambda x:monthlysalescust.loc[x.CustomerID,x.month] if x.CustomerID in monthlysalescust.index else 0,axis=1)\n",
    "test3683['totalsalescust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'totalsalescust'],axis=1)\n",
    "test3683['daysvisitedcust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'daysvisitedcust'],axis=1)\n",
    "test3683['monthsvisitedcust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'monthsvisitedcust'],axis=1)\n",
    "test3683['invoicenoscust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'invoicenoscust'],axis=1)\n",
    "test3683['transacnoscust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'transacnoscust'],axis=1)\n",
    "test3683['avgspendpertranscust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpertranscust'],axis=1)\n",
    "test3683['avgspendperinvoicecust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperinvoicecust'],axis=1)\n",
    "test3683['avgspendperdaycust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperdaycust'],axis=1)\n",
    "test3683['avgspendpermonthcust'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpermonthcust'],axis=1)\n",
    "test3683['custsince'] = test3683.apply(lambda x:custdetails.loc[x.CustomerID,'custsince'],axis=1)\n",
    "\n",
    "\n",
    "above1df = train3683.drop(['StockCode','Description','InvoiceDate','InvoiceNo','hourq', 'monthq', 'weekdayq'],axis=1).copy()\n",
    "above1dfX = above1df.drop('UnitPrice',axis=1)\n",
    "above1dfy = above1df['UnitPrice']\n",
    "\n",
    "mean_enc_column_names = ['month','diffcountry','Country']\n",
    "targenc = category_encoders.OneHotEncoder(cols=mean_enc_column_names)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "xgbr = XGBRegressor(colsample_bytree=0.9 ,gamma= 4,learning_rate= 0.9,max_depth= 14,min_child_weight= 1,n_estimators= 5000,subsample= 0.9,verbosity=0)\n",
    "pipe = Pipeline(steps=[('e', targenc),('s',scaler), ('m', xgbr)])\n",
    "pipe.fit(above1dfX , above1dfy)\n",
    "\n",
    "above1test = test3683.drop(['StockCode','InvoiceDate','InvoiceNo','Description','hourq', 'monthq', 'weekdayq','UnitPrice'],axis=1).copy()\n",
    "test3683['UnitPrice'] = pipe.predict(above1test)\n",
    "\n",
    "test3683.loc[test3683.Quantity>=9,'UnitPrice'] = 18\n",
    "test3683.loc[(test3683.UnitPrice>=12) & (test3683.UnitPrice <=45),'UnitPrice'] = test3683.loc[(test3683.UnitPrice>=12) & (test3683.UnitPrice <=45),'UnitPrice'].apply(lambda x:find_nearest([15,18,28,40],x))\n",
    "\n",
    "test3683.loc[test3683.UnitPrice<=0,'UnitPrice'] = train3683.UnitPrice.median()\n",
    "\n",
    "max3683_32 = df[df.StockCode==3683][df.Country==32].UnitPrice.max()\n",
    "max3683_31 = df[df.StockCode==3683][df.Country==31].UnitPrice.max()\n",
    "test3683.loc[test3683[test3683.Country==32][test3683.UnitPrice>max3683_32].index,'UnitPrice'] = max3683_32\n",
    "test3683.loc[test3683[test3683.Country==31][test3683.UnitPrice>max3683_31].index,'UnitPrice'] = max3683_31\n",
    "\n",
    "test.loc[test3683.index,'UnitPrice'] = test3683['UnitPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model to predict the values of StockCode 3681 items by creating new feature engineered train and test set from all high value StockCode (>=3678). Also adding the high value 3681 points predicted by the earlier model into the train set. Remove one extreme outlier row from train(no match in test). Also assigning some high quantity values with trends from train set. Assign values to solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3681 = df[df.StockCode>=3678].copy() \n",
    "train3681.drop(140723,inplace=True)\n",
    "test3681 = test[test.StockCode==3681][test.UnitPrice.isnull()].copy()\n",
    "\n",
    "train3681['hourq']= pd.cut(train3681.InvoiceDate.dt.hour,bins=hourbin,include_lowest=True,labels=[1,2,3,4,5,6,7],ordered=False)\n",
    "train3681['monthq']=pd.cut(train3681.InvoiceDate.dt.month,bins=monthbin,include_lowest=True,labels=[1,2,3,4,5,6],ordered=False)\n",
    "train3681['weekdayq']=pd.cut(train3681.InvoiceDate.dt.dayofweek,bins=weekdaybin,include_lowest=True,labels=[1,2,3],ordered=False)\n",
    "train3681['monthstart'] = train3681.InvoiceDate.dt.is_month_start\n",
    "train3681['diffcountry'] = np.where(train3681.Country==35,0,1)     \n",
    "\n",
    "train3681['monthlysalescust'] = train3681.apply(lambda x:monthlysalescust.loc[x.CustomerID,x.month] if x.CustomerID in monthlysalescust.index else monthlysalescust.mean()[x.month],axis=1)\n",
    "train3681['totalsalescust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'totalsalescust'] if x.CustomerID in custdetails.index else custdetails.mean()['totalsalescust'],axis=1)\n",
    "train3681['daysvisitedcust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'daysvisitedcust'] if x.CustomerID in custdetails.index else custdetails.mean()['daysvisitedcust'],axis=1)\n",
    "train3681['monthsvisitedcust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'monthsvisitedcust'] if x.CustomerID in custdetails.index else custdetails.mean()['monthsvisitedcust'],axis=1)\n",
    "train3681['invoicenoscust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'invoicenoscust'] if x.CustomerID in custdetails.index else custdetails.mean()['invoicenoscust'],axis=1)\n",
    "train3681['transacnoscust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'transacnoscust'] if x.CustomerID in custdetails.index else custdetails.mean()['transacnoscust'],axis=1)\n",
    "train3681['avgspendpertranscust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpertranscust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendpertranscust'],axis=1)\n",
    "train3681['avgspendperinvoicecust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperinvoicecust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendperinvoicecust'],axis=1)\n",
    "train3681['avgspendperdaycust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperdaycust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendperdaycust'],axis=1)\n",
    "train3681['avgspendpermonthcust'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpermonthcust'] if x.CustomerID in custdetails.index else custdetails.mean()['avgspendpermonthcust'],axis=1)\n",
    "train3681['custsince'] = train3681.apply(lambda x:custdetails.loc[x.CustomerID,'custsince'] if x.CustomerID in custdetails.index else custdetails.mean()['custsince'],axis=1)\n",
    "\n",
    "\n",
    "test3681['month'] = (test3681.InvoiceDate.dt.month.astype('str') + test3681.InvoiceDate.dt.year.astype('str')).astype('category')\n",
    "test3681['hourq']= pd.cut(test3681.InvoiceDate.dt.hour,bins=hourbin,include_lowest=True,labels=[1,2,3,4,5,6,7],ordered=False)\n",
    "test3681['monthq']=pd.cut(test3681.InvoiceDate.dt.month,bins=monthbin,include_lowest=True,labels=[1,2,3,4,5,6],ordered=False)\n",
    "test3681['weekdayq']=pd.cut(test3681.InvoiceDate.dt.dayofweek,bins=weekdaybin,include_lowest=True,labels=[1,2,3],ordered=False)\n",
    "test3681['monthstart'] = test3681.InvoiceDate.dt.is_month_start\n",
    "test3681['diffcountry'] = np.where(test3681.Country==35,0,1) \n",
    "\n",
    "test3681['monthlysalescust'] = test3681.apply(lambda x:monthlysalescust.loc[x.CustomerID,x.month] if x.CustomerID in monthlysalescust.index else 0,axis=1)\n",
    "test3681['totalsalescust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'totalsalescust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['daysvisitedcust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'daysvisitedcust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['monthsvisitedcust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'monthsvisitedcust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['invoicenoscust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'invoicenoscust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['transacnoscust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'transacnoscust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['avgspendpertranscust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpertranscust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['avgspendperinvoicecust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperinvoicecust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['avgspendperdaycust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendperdaycust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['avgspendpermonthcust'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'avgspendpermonthcust'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "test3681['custsince'] = test3681.apply(lambda x:custdetails.loc[x.CustomerID,'custsince'] if x.CustomerID in custdetails.index else 0,axis=1)\n",
    "\n",
    "\n",
    "train3681 = train3681.append(test[test.StockCode==3681][test.UnitPrice>250])\n",
    "\n",
    "\n",
    "above1df = train3681.drop(['StockCode','Description','InvoiceDate','InvoiceNo','hourq', 'monthq', 'weekdayq'],axis=1).copy()\n",
    "above1dfX = above1df.drop('UnitPrice',axis=1)\n",
    "above1dfy = above1df['UnitPrice']\n",
    "\n",
    "mean_enc_column_names = ['month','Country','diffcountry'] #\n",
    "targenc = category_encoders.OneHotEncoder(cols=mean_enc_column_names)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "xgbr = XGBRegressor(colsample_bytree=0.5 ,gamma= 2,learning_rate= 0.01,max_depth= 20,min_child_weight= 1,n_estimators= 500,subsample= 0.9,verbosity=0)\n",
    "pipe = Pipeline(steps=[('e', targenc),('s',scaler), ('m', xgbr)])\n",
    "pipe.fit(above1dfX , above1dfy)\n",
    "\n",
    "above1test = test3681.drop(['StockCode','InvoiceDate','InvoiceNo','Description','UnitPrice','hourq', 'monthq', 'weekdayq'],axis=1).copy()\n",
    "\n",
    "test3681['UnitPrice'] = pipe.predict(above1test)\n",
    "\n",
    "test3681.loc[(test3681.Quantity==-3)&(test3681.StockCode==3681),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity==-3)].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity==-4)&(test3681.StockCode==3681),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity==-4)].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity<=-7)&(test3681.Quantity>=-14)&(test3681.StockCode==3681),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity<=-7)&(df.Quantity>=-14)].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity<=-15)&(test3681.Quantity>=-25)&(test3681.StockCode==3681),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity<=-15)&(df.Quantity>=-25)].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity<=-100)&(test3681.Quantity>=-150)&(test3681.StockCode==3681),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity<=-100)&(df.Quantity>=-150)].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity<=-400)&(test3681.Quantity>=-600)&(test3681.StockCode==3681),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity<=-400)&(df.Quantity>=-600)].UnitPrice.median()\n",
    "\n",
    "test3681.loc[test3681.UnitPrice<0,'UnitPrice'] = df[df.StockCode==3681][df.Quantity>5].UnitPrice.median()\n",
    "\n",
    "test3681.loc[test3681.Quantity>=200,'UnitPrice'] = df[df.StockCode==3681][df.Quantity>=200].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity>=50)&(test3681.Quantity<100),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity>=50)&(df.Quantity<100)].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity>=20)&(test3681.Quantity<50),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity>=20)&(df.Quantity<50)].UnitPrice.median()\n",
    "test3681.loc[(test3681.Quantity>=10)&(test3681.Quantity<20),'UnitPrice'] = df[df.StockCode==3681][(df.Quantity>=10)&(df.Quantity<20)].UnitPrice.median()\n",
    "test3681.loc[test3681.Quantity==6,'UnitPrice'] = df[df.StockCode==3681][df.Quantity==6].UnitPrice.median()\n",
    "test3681.loc[test3681.Quantity==4,'UnitPrice'] = df[df.StockCode==3681][df.Quantity==4].UnitPrice.median()\n",
    "test3681.loc[test3681.Quantity==3,'UnitPrice'] = df[df.StockCode==3681][df.Quantity==3].UnitPrice.median()\n",
    "test3681.loc[test3681.Quantity==2,'UnitPrice'] = df[df.StockCode==3681][df.Quantity==2].UnitPrice.median()\n",
    "\n",
    "test.loc[test3681.index,'UnitPrice'] = test3681['UnitPrice']\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, a few customers were identified having low transactions and quantities and who were judged to be low value spenders in this category in my exploratory analysis with all made features. These people’s transactions were approximated with low values in 2 groups (1 and 5).\n",
    "\n",
    "3681 Stock Customers with no negative quantity and high overall quantity with atleast one Quantity=1 in the test entry would have a relation with their high quantity spends. Their 1 quantity transactions were predicted with their average high quantity transaction value with custom code.\n",
    "\n",
    "Customers who ended their transactions with the store with a high proportion of final transactions in StockCode 3681 had a trend of having a maximum earlier monthly sale value as the UnitPrice in this transaction. Such transactions were appropriately predicted with custom code.\n",
    "\n",
    "Customers with a high negative value for total sales would have approximately that value as UnitPrice in their 1 quantity 3681 entry, to even out the cashflow. Such customers’ transactions were appropriately predicted.\n",
    "For pairs like mentioned above, which had both members in the test set, their predicted values from my model were averaged and assigned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low 3681 UnitPrice customers\n",
    "test.loc[(test.StockCode==3681)&(test.CustomerID.isin([12867,12924,13174,13199,13777,15004,15006])),'UnitPrice'] = 5 #small\n",
    "test.loc[(test.StockCode==3681)&(test.CustomerID.isin([16401,17571,17589,17590,17759])),'UnitPrice'] = 1 #v small\n",
    "\n",
    "#3681 Customers with no negative quantity and high overall quantity with atleast one Quantity=1 test entry\n",
    "combine = df[df.StockCode==3681].append(test[test.StockCode==3681]).copy()\n",
    "one3681cust = combine[(combine.StockCode==3681)].sort_values('InvoiceDate').groupby('CustomerID').apply(lambda x:np.where(((x.Quantity<0).sum()==0)&((x.Quantity==1).sum()>0),x.Quantity.sum(),0))\n",
    "one3681cust = one3681cust[one3681cust>1000].index\n",
    "combine['sale'] = combine.Quantity*combine.UnitPrice\n",
    "hissale = combine[(combine.CustomerID.isin(one3681cust))&(combine.Quantity>1)].groupby('CustomerID').apply(lambda x:x.sale.mean())\n",
    "one3681test = test.loc[(test.StockCode==3681)&(test.CustomerID.isin(one3681cust))&((test.Quantity==1))]\n",
    "test.loc[one3681test.index,'UnitPrice'] = one3681test.apply(lambda x: hissale.loc[x.CustomerID]/x.Quantity,axis=1)\n",
    "\n",
    "#max monthly sale predicted - for customers with high 3681 transactions at end of lifecycle\n",
    "endcustid = test.sort_values('InvoiceDate').groupby('CustomerID').apply(lambda x:(x.tail(5).StockCode==3681).sum())>=3\n",
    "endcustid = endcustid[endcustid].index\n",
    "endtrans = test.loc[(test.CustomerID.isin(endcustid))&(test.StockCode==3681)]\n",
    "endtrans = endtrans.groupby('CustomerID').apply(lambda x:x.InvoiceDate.idxmax())\n",
    "test.loc[endtrans.values,'UnitPrice'] = monthlysalescust.loc[endtrans.index].values.max()\n",
    "\n",
    "#total sale predicted - for customers with low negative total sales \n",
    "leftcustid = custdetails.loc[set(test3681.CustomerID)-(set(test.CustomerID)-set(df.CustomerID)),'totalsalescust']<-100\n",
    "leftcustid = leftcustid[leftcustid].index\n",
    "test.loc[(test.CustomerID.isin(leftcustid))&(test.StockCode==3681),'UnitPrice'] = custdetails.loc[leftcustid,'totalsalescust'].abs().values\n",
    "\n",
    "#averaging predicted values of pairs in test set\n",
    "pairtest = test[test.StockCode==3681].copy()\n",
    "pairtest['Dateint'] = pairtest.Date.astype('int')\n",
    "pairtest['Quantopp'] = -1*pairtest.Quantity\n",
    "pairtest = pairtest.sort_values(['CustomerID','InvoiceDate','Quantopp'])\n",
    "pairtest[\"check\"] = pairtest.groupby([\"CustomerID\", \"Dateint\"]).apply(lambda x:x.loc[::-1, 'Quantity'].cumsum()[::-1]).values\n",
    "pairtest[\"check\"] = np.where(pairtest.check != 0, np.nan, pairtest.check)\n",
    "pairtest[\"check\"] = pairtest[\"check\"].ffill(limit=1)\n",
    "pairtest = pairtest.loc[(pairtest.duplicated([\"CustomerID\", \"Dateint\"], keep=False) & (pairtest.check == 0))]\n",
    "\n",
    "test.loc[pairtest.CustomerID.nlargest(2).index,'UnitPrice'] = test.loc[pairtest.CustomerID.nlargest(2).index,'UnitPrice'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hack to further improve RMSE score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having reached a threshold of deductive and modelling performance, on thinking about how to improve predictions on the high value points in classes >=3678, and by knowing that such points will be only a few dozens, identified such difficult to predict points by exploring high value predictions, points showing high variance in various models, points of high value customers, customers only in test set, pairs(+1,-1) in test set etc. The only tool other than the data was the 10 submissions everyday. Got an idea to make use of it to change the value of one point at a time and make submissions and check for change in RMSE. If RMSE changes, the value can be calculated from the equation of RMSE given that public leaderboard evaluation is on 70% of test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict a point given the before and after value of it and before and after value of RMSE, using the RMSE equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_value(before,after,brmse,armse):\n",
    "    x = symbols('x')\n",
    "    exp = (x-before)**2 - (x-after)**2 - (brmse**2 * len(test) * 0.7 - armse**2 * len(test) * 0.7)\n",
    "    sol = round((float(solve(exp)[0])),2)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All RMSE values used in the below equations can be found under my submissions in the Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting all 6 points in StockCodes 3678,3680 (all were present in evaluation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3678 3680\n",
    "test.loc[49731,'UnitPrice'] = predict_value(450,100,4.227180765,4.39123)\n",
    "test.loc[119628,'UnitPrice'] = predict_value(400,100,4.227180765,4.37025)\n",
    "test.loc[95039,'UnitPrice'] = predict_value(70.8,500,4.227180765,4.45833)\n",
    "test.loc[73177,'UnitPrice'] = predict_value(400,500,4.429052531,4.38692)\n",
    "test.loc[24206,'UnitPrice'] = predict_value(555,400,4.429052531,4.59039)\n",
    "test.loc[102449,'UnitPrice'] = predict_value(459,550,4.429052531,4.43111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of many points checked, under 50 were present in evaluation data and their values are predicted. One extra point could be predicted based on these predictions(Customer 15581 pair point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[72344,'UnitPrice'] = predict_value(1140,2000,16.13864,15.83459)\n",
    "test.loc[76770,'UnitPrice'] = predict_value(1140,2000,16.13864,15.83459)\n",
    "test.loc[62193,'UnitPrice'] = predict_value(1040.24,2000,15.83459,13.73153)\n",
    "test.loc[7460,'UnitPrice'] = predict_value(130.55,1000,11.32559,9.91936)\n",
    "test.loc[42429,'UnitPrice'] = predict_value(1237,603,9.26898,8.97394)\n",
    "test.loc[33972,'UnitPrice'] = predict_value(1237,603,9.26898,8.97394)\n",
    "test.loc[100183,'UnitPrice'] = predict_value(599,100,8.97394,8.79841)\n",
    "test.loc[40273,'UnitPrice'] = predict_value(594,100,8.79841,8.60728)\n",
    "test.loc[63684,'UnitPrice'] = predict_value(36.3,200,4.227180765,4.27505)\n",
    "test.loc[32497,'UnitPrice'] = predict_value(36.3,200,4.227180765,4.26082)\n",
    "test.loc[91137,'UnitPrice'] = predict_value(235.01,1000,8.55068,7.16962)\n",
    "test.loc[73245,'UnitPrice'] = predict_value(187,1000,6.04810,5.61940)\n",
    "test.loc[120315,'UnitPrice'] = predict_value(75,1000,5.61940,5.60381)\n",
    "test.loc[53855,'UnitPrice'] = predict_value(320,7,5.31560,5.20236)\n",
    "test.loc[120623,'UnitPrice'] = predict_value(57,1000,6.60924,6.04810)\n",
    "test.loc[19420,'UnitPrice'] = predict_value(891,50,5.20236,6.31479)\n",
    "test.loc[44327,'UnitPrice'] = predict_value(489,4.95,5.20236,4.94291)\n",
    "test.loc[102910,'UnitPrice'] = predict_value(441,5,4.94291,4.71038)\n",
    "test.loc[40001,'UnitPrice'] = predict_value(50,150,4.227180765,4.15741)\n",
    "test.loc[102521,'UnitPrice'] = predict_value(7.6,30,4.227180765,4.2258655)\n",
    "test.loc[88113,'UnitPrice'] = predict_value(137.648,500,4.227180765,4.53580)\n",
    "test.loc[36143,'UnitPrice'] = df[df.CustomerID==15581][df.StockCode==3681][df.Quantity==-1].UnitPrice.values[0]\n",
    "test.loc[114586,'UnitPrice'] = predict_value(134,200,4.227180765,4.24170)\n",
    "test.loc[33277,'UnitPrice'] = predict_value(134,200,4.227180765,4.24311)\n",
    "test.loc[16343,'UnitPrice'] = predict_value(125.782524,18.92,4.227180765,4.20857)\n",
    "test.loc[99987,'UnitPrice'] = predict_value(122.7615,8.54,4.22718,4.21111)\n",
    "test.loc[84925,'UnitPrice'] = predict_value(79.4,500,4.22718,4.45369)\n",
    "test.loc[33147,'UnitPrice'] = predict_value(60,500,4.22718,4.53845)\n",
    "test.loc[7781,'UnitPrice'] = predict_value(40.341488,500,4.227180765,4.29119)\n",
    "test.loc[100447,'UnitPrice'] = predict_value(202.94,3060.5788,4.227180765,10.79092)\n",
    "test.loc[21332,'UnitPrice'] = predict_value(40.46,410.827667,4.227180765,4.41301) #same\n",
    "test.loc[117278,'UnitPrice'] = predict_value(549.34,410.827667,4.227180765,4.25366) #same\n",
    "test.loc[84925,'UnitPrice'] = predict_value(79.40591,169.62036,4.227180765,4.23579)\n",
    "test.loc[100183,'UnitPrice'] = predict_value(82.43,164.6,4.22718,4.2365) #same\n",
    "test.loc[3696,'UnitPrice'] = predict_value(27.5,151.4474,4.22718,4.23591)\n",
    "test.loc[8097,'UnitPrice'] = predict_value(84.8,147.359,4.22718,4.24552)\n",
    "test.loc[53606,'UnitPrice'] = predict_value(75,142,4.227180765,4.22041)\n",
    "test.loc[58791,'UnitPrice'] = predict_value(35,500,4.227180765,3.84496)\n",
    "test.loc[102521,'UnitPrice'] = predict_value(7.6,500,4.227180765,4.50927)\n",
    "test.loc[50554,'UnitPrice'] = predict_value(15,500,4.227180765,4.51422)\n",
    "test.loc[113281,'UnitPrice'] = predict_value(3.15,500,4.227180765,4.54612)\n",
    "test.loc[20337,'UnitPrice'] = predict_value(28,500,4.227180765,4.17987)\n",
    "test.loc[71598,'UnitPrice'] = predict_value(102.24,500,4.227180765,4.53136)\n",
    "test.loc[26683,'UnitPrice'] = predict_value(57.60,500,4.227180765,4.50411)\n",
    "test.loc[111923,'UnitPrice'] = predict_value(33.75,250,4.227180765,4.27227)\n",
    "test.loc[81949,'UnitPrice'] = predict_value(5.849,1000,4.227180765,3.11874)\n",
    "test.loc[3319,'UnitPrice'] = predict_value(169.268,500,4.227180765,4.51962)\n",
    "test.loc[96839,'UnitPrice'] = predict_value(31.298,468.9,4.227180765,3.95836) \n",
    "test.loc[78679,'UnitPrice'] = predict_value(39.2,185.36,4.227180765,4.27221)\n",
    "test.loc[110244,'UnitPrice'] = predict_value(37.3678,5.48,4.227180765,4.22532)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving final submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['UnitPrice']].to_csv('Solution_HarikrishnanV_Rank6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
